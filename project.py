# -*- coding: utf-8 -*-
"""Himanshu_Sharma_Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1O5pCxnt5gt-PvPq3WjWs0aax8bbM_3yn
"""

import os
import matplotlib.pyplot as plt
import numpy as np
import natsort
import pandas as pd 
import scipy
import shutil
import cv2
import math

imageFolderPath='/content/drive/MyDrive/AWaDH agriculture CPS/Project/dataset/'
labelPath='/content/drive/MyDrive/AWaDH agriculture CPS/Project/Dataset.csv.csv'

sortImageDir=natsort.natsorted(os.listdir(imageFolderPath),reverse=False)
len(sortImageDir)
new_w, new_h=96,96

resizeAll=[]
for file in sortImageDir:
    print(file)
    filePath=imageFolderPath+file
    frame=cv2.imread(filePath)/255
    resize = cv2.resize(frame, (new_w, new_h))
    resizeAll.append(resize)

len(resizeAll)
resizeAll=np.asarray(resizeAll)

resizeAll.shape

### show an image
plt.imshow(resizeAll[344,:,:,:])

# read label from csv

temp=pd.read_csv(labelPath,header=None,skiprows=1,index_col=0)

# temp.head()
label=temp.values
print(type(label))
print(label)

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(resizeAll, label, random_state=101,shuffle=True)

# X_train.shape
y_train.shape
X_train.ndim

# Convolutional Neural Network
from tensorflow.keras.utils import plot_model
from keras.models import Model
from keras.layers import Input
from keras.layers import Dense
from keras.layers import Flatten
from keras.layers.convolutional import Conv2D
from keras.layers.pooling import MaxPooling2D
from keras.layers import ZeroPadding2D

visible = Input(shape=(96,96,3),name='ip')
conv1 = Conv2D(32, kernel_size=3, strides=(1,1), padding="valid", activation='relu',name='cn1')(visible)
pool1 = MaxPooling2D(pool_size=(3, 3),strides=(2,2), padding="valid",name='pl1')(conv1)

conv2 = Conv2D(16, kernel_size=5, strides=(2,2), padding="valid", activation='relu',name='cn2')(pool1)
pool2 = MaxPooling2D(pool_size=(3, 3),strides=(2,2), padding="valid",name='pl2')(conv2)

flat = Flatten(name='flat')(pool2)
hidden1 = Dense(10, activation='relu',name='hd1')(flat)
output = Dense(4, activation='softmax',name='op')(hidden1)
my_model = Model(inputs=visible, outputs=output)


# summarize layers
print(my_model.summary())
# plot graph
plot_model(my_model, to_file='convolutional_neural_network.png',show_shapes=True, show_layer_names=True)

# compile the keras model
import tensorflow
from tensorflow.keras.optimizers import SGD, RMSprop, Adam, Adadelta, Adagrad, Adamax, Nadam
#my_model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.0001), metrics=['accuracy','mse','mae'])
my_model.compile(optimizer='adam',loss = tensorflow.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy','mse','mae'])

my_history= my_model.fit(X_train, y_train, epochs=50, batch_size=8,verbose=1, validation_split=0.1)

# plot loss
from matplotlib import pyplot
pyplot.subplot(411)
pyplot.title('loss plot ')
pyplot.plot(my_history.history['loss'], label='train')
pyplot.plot(my_history.history['val_loss'], label='val')
pyplot.legend()
pyplot.show()

# plot acc during training
pyplot.subplot(412)
pyplot.title('accuracy plot')
pyplot.plot(my_history.history['accuracy'], label='train')
pyplot.plot(my_history.history['val_accuracy'], label='test')
pyplot.legend()
pyplot.show()

# plot acc during training
pyplot.subplot(412)
pyplot.title('mse plot')
pyplot.plot(my_history.history['mse'], label='train')
pyplot.plot(my_history.history['val_mse'], label='test')
pyplot.legend()
pyplot.show()

# plot acc during training
pyplot.subplot(412)
pyplot.title('mae plot')
pyplot.plot(my_history.history['mae'], label='train')
pyplot.plot(my_history.history['val_mae'], label='test')
pyplot.legend()
pyplot.show()

import keras
# make class predictions with the model
y_pred = my_model.predict(X_test)

keras.metrics.categorical_accuracy(y_test, y_pred)

score = my_model.evaluate(X_test, y_test, verbose=1)
print("%s: %.2f%%" % (my_model.metrics_names[1], score[1]*100))